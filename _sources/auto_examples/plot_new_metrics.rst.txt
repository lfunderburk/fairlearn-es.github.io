
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/plot_new_metrics.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_auto_examples_plot_new_metrics.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_plot_new_metrics.py:


================================
Métricas con múltiples funciones
================================

.. GENERATED FROM PYTHON SOURCE LINES 10-53

Este notebook muestra la nueva API para métricas, que admite
múltiples características sensibles y condicionales. Este ejemplo no
contiene una discusión adecuada sobre cómo la justicia se relaciona con el conjunto de datos
utilizado, aunque resalta problemas que los usuarios pueden querer
considere al analizar sus conjuntos de datos.

Vamos a considerar un escenario de préstamo de crédito, suponiendo que tengamos
un modelo que predice si un cliente en particular
va a reembolsar un préstamo. Esto podría utilizarse como base para decidir si
o no ofrecer un préstamo a ese cliente. Con métricas tradicionales,
evaluaríamos el modelo usando:

- Los valores 'verdaderos' del conjunto de prueba
- Las predicciones del modelo del conjunto de prueba

Nuestras métricas de equidad calculan estadísticas de equidad basadas en grupos.
Para usar estos, también necesitamos columnas categóricas del conjunto de prueba.
Para este ejemplo, incluiremos:

- El sexo de cada individuo (dos valores únicos)
- La raza de cada individuo (tres valores únicos)
- La categoría de puntaje crediticio de cada individuo (tres valores únicos)
- Si el préstamo se considera 'grande' o 'pequeño'

El sexo y la raza de una persona no deben afectar la decisión de un préstamo,
pero sería legítimo considerar el puntaje crediticio de una persona
y el tamaño relativo del préstamo que deseaban.

Un escenario real será más complicado, pero esto servirá para
ilustrar el uso de las nuevas métricas.

Obteniendo los datos
====================

*Esta sección se puede omitir. Simplemente crea un conjunto de datos para
fines ilustrativos*

Utilizaremos el conocido conjunto de datos UCI 'Adult' como base de este
demostración. Esto no es para un escenario de préstamos, pero consideraremos
como uno para los propósitos de este ejemplo. Usaremos el existente
columnas 'raza' y 'sexo' (recortando la primera a tres valores únicos),
y fabrique bandas de puntaje crediticio y tamaños de préstamos a partir de otras columnas.
Comenzamos con algunas declaraciones de `importación`:

.. GENERATED FROM PYTHON SOURCE LINES 53-71

.. code-block:: default


    import functools
    import numpy as np

    import sklearn.metrics as skm
    from sklearn.compose import ColumnTransformer
    from sklearn.datasets import fetch_openml
    from sklearn.impute import SimpleImputer
    from sklearn.linear_model import LogisticRegression
    from sklearn.model_selection import train_test_split
    from sklearn.preprocessing import StandardScaler, OneHotEncoder
    from sklearn.compose import make_column_selector as selector
    from sklearn.pipeline import Pipeline

    from fairlearn.metrics import MetricFrame
    from fairlearn.metrics import selection_rate, count









.. GENERATED FROM PYTHON SOURCE LINES 72-73

A continuación, importamos los datos:

.. GENERATED FROM PYTHON SOURCE LINES 73-78

.. code-block:: default


    data = fetch_openml(data_id=1590, as_frame=True)
    X_raw = data.data
    y = (data.target == ">50K") * 1








.. GENERATED FROM PYTHON SOURCE LINES 79-81

Para mayor claridad, consolidamos la columna 'raza' para tener
tres valores únicos:

.. GENERATED FROM PYTHON SOURCE LINES 81-96

.. code-block:: default



    def race_transform(input_str):
        """Reduce values to White, Black and Other."""
        result = "Other"
        if input_str == "White" or input_str == "Black":
            result = input_str
        return result


    X_raw["race"] = (
        X_raw["race"].map(race_transform).fillna("Other").astype("category")
    )
    print(np.unique(X_raw["race"]))





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    /Users/laura.gf/github/Fairlearn-es/examples/plot_new_metrics.py:92: SettingWithCopyWarning: 
    A value is trying to be set on a copy of a slice from a DataFrame.
    Try using .loc[row_indexer,col_indexer] = value instead

    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
      X_raw["race"].map(race_transform).fillna("Other").astype("category")
    ['Black' 'Other' 'White']




.. GENERATED FROM PYTHON SOURCE LINES 97-101

Después, fabricamos las columnas para la banda de calificación crediticia y
tamaño del préstamo solicitado. Estos están hipotéticos, y no
parte del conjunto de datos real de alguna manera. Son simplemente para
fines ilustrativos.

.. GENERATED FROM PYTHON SOURCE LINES 101-131

.. code-block:: default



    def marriage_transform(m_s_string):
        """Perform some simple manipulations."""
        result = "Low"
        if m_s_string.startswith("Married"):
            result = "Medium"
        elif m_s_string.startswith("Widowed"):
            result = "High"
        return result


    def occupation_transform(occ_string):
        """Perform some simple manipulations."""
        result = "Small"
        if occ_string.startswith("Machine"):
            result = "Large"
        return result


    col_credit = X_raw["marital-status"].map(marriage_transform).fillna("Low")
    col_credit.name = "Credit Score"
    col_loan_size = X_raw["occupation"].map(occupation_transform).fillna("Small")
    col_loan_size.name = "Loan Size"

    A = X_raw[["race", "sex"]]
    A["Credit Score"] = col_credit
    A["Loan Size"] = col_loan_size
    A





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    /Users/laura.gf/github/Fairlearn-es/examples/plot_new_metrics.py:127: SettingWithCopyWarning: 
    A value is trying to be set on a copy of a slice from a DataFrame.
    Try using .loc[row_indexer,col_indexer] = value instead

    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
      A["Credit Score"] = col_credit
    /Users/laura.gf/github/Fairlearn-es/examples/plot_new_metrics.py:128: SettingWithCopyWarning: 
    A value is trying to be set on a copy of a slice from a DataFrame.
    Try using .loc[row_indexer,col_indexer] = value instead

    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
      A["Loan Size"] = col_loan_size


.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <div>
    <style scoped>
        .dataframe tbody tr th:only-of-type {
            vertical-align: middle;
        }

        .dataframe tbody tr th {
            vertical-align: top;
        }

        .dataframe thead th {
            text-align: right;
        }
    </style>
    <table border="1" class="dataframe">
      <thead>
        <tr style="text-align: right;">
          <th></th>
          <th>race</th>
          <th>sex</th>
          <th>Credit Score</th>
          <th>Loan Size</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <th>0</th>
          <td>Black</td>
          <td>Male</td>
          <td>Low</td>
          <td>Large</td>
        </tr>
        <tr>
          <th>1</th>
          <td>White</td>
          <td>Male</td>
          <td>Medium</td>
          <td>Small</td>
        </tr>
        <tr>
          <th>2</th>
          <td>White</td>
          <td>Male</td>
          <td>Medium</td>
          <td>Small</td>
        </tr>
        <tr>
          <th>3</th>
          <td>Black</td>
          <td>Male</td>
          <td>Medium</td>
          <td>Large</td>
        </tr>
        <tr>
          <th>4</th>
          <td>White</td>
          <td>Female</td>
          <td>Low</td>
          <td>Small</td>
        </tr>
        <tr>
          <th>...</th>
          <td>...</td>
          <td>...</td>
          <td>...</td>
          <td>...</td>
        </tr>
        <tr>
          <th>48837</th>
          <td>White</td>
          <td>Female</td>
          <td>Medium</td>
          <td>Small</td>
        </tr>
        <tr>
          <th>48838</th>
          <td>White</td>
          <td>Male</td>
          <td>Medium</td>
          <td>Large</td>
        </tr>
        <tr>
          <th>48839</th>
          <td>White</td>
          <td>Female</td>
          <td>High</td>
          <td>Small</td>
        </tr>
        <tr>
          <th>48840</th>
          <td>White</td>
          <td>Male</td>
          <td>Low</td>
          <td>Small</td>
        </tr>
        <tr>
          <th>48841</th>
          <td>White</td>
          <td>Female</td>
          <td>Medium</td>
          <td>Small</td>
        </tr>
      </tbody>
    </table>
    <p>48842 rows × 4 columns</p>
    </div>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 132-137

Ahora que hemos importado nuestro conjunto de datos y fabricado algunas funciones,
podemos realizar un procesamiento más convencional. Para evitar el problema de
`fuga de datos <https://en.wikipedia.org/wiki/Leakage_ (machine_learning)>`_,
necesitamos dividir los datos en conjuntos de prueba y entrenamiento antes de aplicar
cualquier transformación o escala:

.. GENERATED FROM PYTHON SOURCE LINES 137-152

.. code-block:: default


    (X_train, X_test, y_train, y_test, A_train, A_test) = train_test_split(
        X_raw, y, A, test_size=0.3, random_state=54321, stratify=y
    )

    # Asegúrese de que los índices estén alineados entre X, y, A,
    # después de seleccionar y dividir el marco de datos en Series.

    X_train = X_train.reset_index(drop=True)
    X_test = X_test.reset_index(drop=True)
    y_train = y_train.reset_index(drop=True)
    y_test = y_test.reset_index(drop=True)
    A_train = A_train.reset_index(drop=True)
    A_test = A_test.reset_index(drop=True)








.. GENERATED FROM PYTHON SOURCE LINES 153-162

A continuación, construimos dos objetos :class:`~ sklearn.pipeline.Pipeline`
para procesar las columnas, una para datos numéricos y la otra
para datos categóricos. Ambos imputan valores perdidos; la diferencia
es si los datos están escalados (columnas numéricas) o
tienen codificación one-hot (columnas categóricas). Imputación de
valores faltantes generalmente deben hacerse con cuidado, ya que esto podría
introducir sesgos potencialmente. Por supuesto, eliminar filas con
los datos faltantes también puede causar problemas, si subgrupos particulares
tienen datos de peor calidad.

.. GENERATED FROM PYTHON SOURCE LINES 162-179

.. code-block:: default


    numeric_transformer = Pipeline(
        steps=[("impute", SimpleImputer()), ("scaler", StandardScaler())]
    )
    categorical_transformer = Pipeline(
        [
            ("impute", SimpleImputer(strategy="most_frequent")),
            ("ohe", OneHotEncoder(handle_unknown="ignore"))
        ]
    )
    preprocessor = ColumnTransformer(
        transformers=[
            ("num", numeric_transformer, selector(dtype_exclude="category")),
            ("cat", categorical_transformer, selector(dtype_include="category"))
        ]
    )








.. GENERATED FROM PYTHON SOURCE LINES 180-182

Con nuestro preprocesador definido, ahora podemos construir un
nueva canalización que incluye un Estimador:

.. GENERATED FROM PYTHON SOURCE LINES 182-193

.. code-block:: default


    unmitigated_predictor = Pipeline(
        steps=[
            ("preprocessor", preprocessor),
            (
                "classifier",
                LogisticRegression(solver="liblinear", fit_intercept=True)
            )
        ]
    )








.. GENERATED FROM PYTHON SOURCE LINES 194-197

Con la pipeline (tubería) completamente definida, primero podemos entrenarla
con los datos de entrenamiento y luego generar predicciones
utilizando los datos de prueba.

.. GENERATED FROM PYTHON SOURCE LINES 197-202

.. code-block:: default


    unmitigated_predictor.fit(X_train, y_train)
    y_pred = unmitigated_predictor.predict(X_test)









.. GENERATED FROM PYTHON SOURCE LINES 203-219

Analizando el modelo con métricas
================================

Después del formateo de datos y entrenamiento de modelos, tenemos lo siguiente
de nuestro conjunto de prueba:

- Un vector de valores verdaderos llamado ``y_test``
- Un vector de predicciones del modelo llamado ``y_pred``
- Un DataFrame (tabla de datos) con características categóricas relevantes para la equidad llamado ``A_test``

Si fuésemos a utilizar un análisis de modelo tradicional, utilizaríamos algunas métricas
que evalúan el conjunto de datos completo. Supongamos que en este caso,
las métricas relevantes son :func:`fairlearn.metrics.selection_rate` y
:func:`sklearn.metrics.fbeta_score` (con
`beta = 0.6``).
Podemos evaluar estas métricas directamente:

.. GENERATED FROM PYTHON SOURCE LINES 219-223

.. code-block:: default


    print("Selection Rate:", selection_rate(y_test, y_pred))
    print("fbeta:", skm.fbeta_score(y_test, y_pred, beta=0.6))





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    Selection Rate: 0.1947041561454992
    fbeta: 0.6827826864569057




.. GENERATED FROM PYTHON SOURCE LINES 224-229

Sabemos que hay características sensibles en nuestros datos y queremos
asegurarnos de no dañar a las personas debido a su membresía en
estos grupos. Para este propósito, Fairlearn proporciona la clase
:class:`fairlearn.metrics.MetricFrame`. Construyamos una instancia de esta clase y luego miremos
sus capacidades:

.. GENERATED FROM PYTHON SOURCE LINES 229-245

.. code-block:: default


    fbeta_06 = functools.partial(skm.fbeta_score, beta=0.6, zero_division=1)

    metric_fns = {
        "selection_rate": selection_rate,
        "fbeta_06": fbeta_06,
        "count": count
    }

    grouped_on_sex = MetricFrame(
        metrics=metric_fns,
        y_true=y_test,
        y_pred=y_pred,
        sensitive_features=A_test["sex"]
    )








.. GENERATED FROM PYTHON SOURCE LINES 246-267

La clase :class:`fairlearn.metrics.MetricFrame` requiere un
mínimo de cuatro argumentos:

1. Las funciones métricas que se evaluarán
2. Los valores verdaderos
3. Los valores predichos
4. Los valores de las características sensibles

Todos estos se pasan como argumentos al constructor. Si más de una métrica
se requiere(como en este caso), entonces debemos
proporcionarlos en un diccionario.

Las métricas deben tener una firma ``fn (y_true, y_pred)``,
entonces tenemos que usar :func:`functools.partial` en ``fbeta_score()`` para
proporcionar ``beta = 0.6`` (mostraremos cómo pasar una lista con
argumentos como ponderaciones de muestra en breve).

Ahora echaremos un vistazo más de cerca a :class:`fairlearn.metrics.MetricFrame`.
Primero, está la propiedad ``overall``, que contiene
las métricas evaluadas en el conjunto de datos completo. Vemos que esto contiene el
mismos valores calculados anteriormente:

.. GENERATED FROM PYTHON SOURCE LINES 267-276

.. code-block:: default


    assert grouped_on_sex.overall["selection_rate"] == selection_rate(
        y_test, y_pred
    )
    assert grouped_on_sex.overall["fbeta_06"] == skm.fbeta_score(
        y_test, y_pred, beta=0.6
    )
    print(grouped_on_sex.overall)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    selection_rate    0.194704
    fbeta_06          0.682783
    count                14653
    dtype: object




.. GENERATED FROM PYTHON SOURCE LINES 277-282

La otra propiedad en :class:`fairlearn.metrics.MetricFrame`
es ``by_group``, el cual contiene las métricas evaluadas en cada subgrupo definido
por las categorías en el argumento ``sensitive_features =``. Tenga en cuenta que
:func:`fairlearn.metrics.count` se puede usar para mostrar el número de
puntos de datos en cada subgrupo. En este caso, tenemos resultados para hombres y mujeres:

.. GENERATED FROM PYTHON SOURCE LINES 282-285

.. code-block:: default


    grouped_on_sex.by_group






.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <div>
    <style scoped>
        .dataframe tbody tr th:only-of-type {
            vertical-align: middle;
        }

        .dataframe tbody tr th {
            vertical-align: top;
        }

        .dataframe thead th {
            text-align: right;
        }
    </style>
    <table border="1" class="dataframe">
      <thead>
        <tr style="text-align: right;">
          <th></th>
          <th>selection_rate</th>
          <th>fbeta_06</th>
          <th>count</th>
        </tr>
        <tr>
          <th>sex</th>
          <th></th>
          <th></th>
          <th></th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <th>Female</th>
          <td>0.06883</td>
          <td>0.634014</td>
          <td>4838</td>
        </tr>
        <tr>
          <th>Male</th>
          <td>0.25675</td>
          <td>0.689789</td>
          <td>9815</td>
        </tr>
      </tbody>
    </table>
    </div>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 286-291

Podemos ver inmediatamente una disparidad sustancial en la tasa de selección entre
masculinos y femeninos.

También podemos crear otro objeto :class:`fairlearn.metrics.MetricFrame`
usando la raza como característica sensible:

.. GENERATED FROM PYTHON SOURCE LINES 291-299

.. code-block:: default


    grouped_on_race = MetricFrame(
        metrics=metric_fns,
        y_true=y_test,
        y_pred=y_pred,
        sensitive_features=A_test["race"]
    )








.. GENERATED FROM PYTHON SOURCE LINES 300-301

La propiedad ``overall`` no cambia:

.. GENERATED FROM PYTHON SOURCE LINES 301-304

.. code-block:: default


    assert (grouped_on_sex.overall == grouped_on_race.overall).all()








.. GENERATED FROM PYTHON SOURCE LINES 305-306

La propiedad ``by_group`` ahora contiene las métricas evaluadas según la columna 'raza':

.. GENERATED FROM PYTHON SOURCE LINES 306-309

.. code-block:: default


    grouped_on_race.by_group






.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <div>
    <style scoped>
        .dataframe tbody tr th:only-of-type {
            vertical-align: middle;
        }

        .dataframe tbody tr th {
            vertical-align: top;
        }

        .dataframe thead th {
            text-align: right;
        }
    </style>
    <table border="1" class="dataframe">
      <thead>
        <tr style="text-align: right;">
          <th></th>
          <th>selection_rate</th>
          <th>fbeta_06</th>
          <th>count</th>
        </tr>
        <tr>
          <th>race</th>
          <th></th>
          <th></th>
          <th></th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <th>Black</th>
          <td>0.068198</td>
          <td>0.592125</td>
          <td>1437</td>
        </tr>
        <tr>
          <th>Other</th>
          <td>0.16763</td>
          <td>0.693717</td>
          <td>692</td>
        </tr>
        <tr>
          <th>White</th>
          <td>0.210715</td>
          <td>0.686081</td>
          <td>12524</td>
        </tr>
      </tbody>
    </table>
    </div>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 310-312

Vemos que también existe una disparidad significativa en las tasas de selección cuando
agrupación por raza.

.. GENERATED FROM PYTHON SOURCE LINES 314-331

Muestras de pesos y otras matrices
----------------------------------

Observamos anteriormente que las funciones métricas subyacentes pasaron al
constructor :class:`fairlearn.metrics.MetricFrame` debe ser de
la forma ``fn (y_true, y_pred)`` - no admitimos argumentos escalares
como ``pos_label =`` o ``beta =`` en el constructor. Dichos
argumentos deben estar vinculados a una nueva función usando
:func:`functools.partial`, junto con el resultado. Sin embargo, Fairlearn también apoya
argumentos que tienen solo un elemento por cada muestra, con una matriz
de pesos de muestra es el ejemplo más común. Estos están divididos
en subgrupos junto con ``y_true`` y ``y_pred``, y se pasan
a la métrica subyacente.

Para usar estos argumentos, pasamos en un diccionario como `` sample_params =``
argumento del constructor. Generemos algunos pesos aleatorios y
pásales estos:

.. GENERATED FROM PYTHON SOURCE LINES 331-348

.. code-block:: default


    random_weights = np.random.rand(len(y_test))

    example_sample_params = {
        "selection_rate": {"sample_weight": random_weights},
        "fbeta_06": {"sample_weight": random_weights}
    }


    grouped_with_weights = MetricFrame(
        metrics=metric_fns,
        y_true=y_test,
        y_pred=y_pred,
        sensitive_features=A_test["sex"],
        sample_params=example_sample_params
    )








.. GENERATED FROM PYTHON SOURCE LINES 349-350

Podemos inspeccionar los valores generales y verificar que sean los esperados:

.. GENERATED FROM PYTHON SOURCE LINES 350-359

.. code-block:: default


    assert grouped_with_weights.overall["selection_rate"] == selection_rate(
        y_test, y_pred, sample_weight=random_weights
    )
    assert grouped_with_weights.overall["fbeta_06"] == skm.fbeta_score(
        y_test, y_pred, beta=0.6, sample_weight=random_weights
    )
    print(grouped_with_weights.overall)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    selection_rate    0.193529
    fbeta_06           0.68269
    count                14653
    dtype: object




.. GENERATED FROM PYTHON SOURCE LINES 360-361

También podemos ver el efecto sobre la métrica que se evalúa en los subgrupos:

.. GENERATED FROM PYTHON SOURCE LINES 361-364

.. code-block:: default


    grouped_with_weights.by_group






.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <div>
    <style scoped>
        .dataframe tbody tr th:only-of-type {
            vertical-align: middle;
        }

        .dataframe tbody tr th {
            vertical-align: top;
        }

        .dataframe thead th {
            text-align: right;
        }
    </style>
    <table border="1" class="dataframe">
      <thead>
        <tr style="text-align: right;">
          <th></th>
          <th>selection_rate</th>
          <th>fbeta_06</th>
          <th>count</th>
        </tr>
        <tr>
          <th>sex</th>
          <th></th>
          <th></th>
          <th></th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <th>Female</th>
          <td>0.070202</td>
          <td>0.63873</td>
          <td>4838</td>
        </tr>
        <tr>
          <th>Male</th>
          <td>0.255199</td>
          <td>0.689246</td>
          <td>9815</td>
        </tr>
      </tbody>
    </table>
    </div>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 365-382

Cuantificación de disparidades
==============================

Ahora sabemos que nuestro modelo está seleccionando individuos que son mujeres mucho menos
a menudo que los hombres. Hay un efecto similar cuando
examinando los resultados por raza, y los negros son seleccionados con mucha menos frecuencia que
blancos (y los clasificados como 'otros'). Sin embargo, hay muchos casos en los que
presentar todos estos números a la vez no será útil (por ejemplo, un
tablero de alto nivel que monitorea el desempeño del modelo). Fairlearn ofrece
varios medios de agregar métricas en los subgrupos, de modo que las disparidades
pueden cuantificarse fácilmente.

La más simple de estas agregaciones es ``group_min()``, que informa el
valor mínimo visto para un subgrupo para cada métrica subyacente (también proporcionamos
``group_max()``). Esto es
útil si hay un mandato de que "ningún subgrupo debe tener un ``fbeta_score()``
de menos de 0.6". Podemos evaluar los valores mínimos fácilmente:

.. GENERATED FROM PYTHON SOURCE LINES 382-385

.. code-block:: default


    grouped_on_race.group_min()





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none


    selection_rate    0.068198
    fbeta_06          0.592125
    count                  692
    dtype: object



.. GENERATED FROM PYTHON SOURCE LINES 386-390

Como se señaló anteriormente, las tasas de selección varían mucho según la raza y el sexo.
Esto se puede cuantificar en términos de una diferencia entre el subgrupo con
el valor más alto de la métrica y el subgrupo con el valor más bajo.
Para esto, proporcionamos el método ``difference(method ='between_groups)``:

.. GENERATED FROM PYTHON SOURCE LINES 390-393

.. code-block:: default


    grouped_on_race.difference(method="between_groups")





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none


    selection_rate    0.142518
    fbeta_06          0.101591
    count                11832
    dtype: object



.. GENERATED FROM PYTHON SOURCE LINES 394-397

También podemos evaluar la diferencia relativa que corresponde al
valor total de la métrica. En este caso tomamos el valor absoluto, de modo que el
el resultado es siempre positivo:

.. GENERATED FROM PYTHON SOURCE LINES 397-400

.. code-block:: default


    grouped_on_race.difference(method="to_overall")





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none


    selection_rate    0.126507
    fbeta_06          0.090657
    count                13961
    dtype: object



.. GENERATED FROM PYTHON SOURCE LINES 401-404

Hay situaciones en las que conocer los radios de las métricas evaluadas en
los subgrupos es más útil. Para ello tenemos el método ``ratio()``.
Podemos tomar las relaciones entre los valores mínimo y máximo de cada métrica:

.. GENERATED FROM PYTHON SOURCE LINES 404-407

.. code-block:: default


    grouped_on_race.ratio(method="between_groups")





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none


    selection_rate    0.323648
    fbeta_06          0.853555
    count             0.055254
    dtype: object



.. GENERATED FROM PYTHON SOURCE LINES 408-411

También podemos calcular los radios relativos al valor general de cada
métrica. De manera análoga a las diferencias, las proporciones están siempre en el rango
:math: `[0,1]`:

.. GENERATED FROM PYTHON SOURCE LINES 411-414

.. code-block:: default


    grouped_on_race.ratio(method="to_overall")





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none


    selection_rate    0.350263
    fbeta_06          0.867223
    count             0.047226
    dtype: float64



.. GENERATED FROM PYTHON SOURCE LINES 415-428

Intersección de características
=================================

Hasta ahora, solo hemos considerado una característica sensible a la vez,
y ya hemos encontrado algunos problemas graves en nuestros datos de ejemplo.
Sin embargo, a veces se pueden esconder problemas graves en las intersecciones de
características. Por ejemplo, el
`Proyecto Gender Shades <https://www.media.mit.edu/projects/gender-shades/overview/>`_
descubrió que los algoritmos de reconocimiento facial funcionaban peor para los negros
que los blancos, y también peor para las mujeres que para los hombres (a pesar de la alta
puntuación de precisión). Además, el rendimiento en mujeres negras fue *terrible*.
Podemos examinar las intersecciones de características sensibles pasando
varias columnas para el constructor :class:`fairlearn.metrics.MetricFrame`:

.. GENERATED FROM PYTHON SOURCE LINES 428-436

.. code-block:: default


    grouped_on_race_and_sex = MetricFrame(
        metrics=metric_fns,
        y_true=y_test,
        y_pred=y_pred,
        sensitive_features=A_test[["race", "sex"]]
    )








.. GENERATED FROM PYTHON SOURCE LINES 437-439

Los valores generales no han cambiado, pero la tabla ``by_group`` ahora
muestra las intersecciones entre subgrupos:

.. GENERATED FROM PYTHON SOURCE LINES 439-443

.. code-block:: default


    assert (grouped_on_race_and_sex.overall == grouped_on_race.overall).all()
    grouped_on_race_and_sex.by_group






.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <div>
    <style scoped>
        .dataframe tbody tr th:only-of-type {
            vertical-align: middle;
        }

        .dataframe tbody tr th {
            vertical-align: top;
        }

        .dataframe thead th {
            text-align: right;
        }
    </style>
    <table border="1" class="dataframe">
      <thead>
        <tr style="text-align: right;">
          <th></th>
          <th></th>
          <th>selection_rate</th>
          <th>fbeta_06</th>
          <th>count</th>
        </tr>
        <tr>
          <th>race</th>
          <th>sex</th>
          <th></th>
          <th></th>
          <th></th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <th rowspan="2" valign="top">Black</th>
          <th>Female</th>
          <td>0.032258</td>
          <td>0.630316</td>
          <td>713</td>
        </tr>
        <tr>
          <th>Male</th>
          <td>0.103591</td>
          <td>0.580624</td>
          <td>724</td>
        </tr>
        <tr>
          <th rowspan="2" valign="top">Other</th>
          <th>Female</th>
          <td>0.070866</td>
          <td>0.503704</td>
          <td>254</td>
        </tr>
        <tr>
          <th>Male</th>
          <td>0.223744</td>
          <td>0.728972</td>
          <td>438</td>
        </tr>
        <tr>
          <th rowspan="2" valign="top">White</th>
          <th>Female</th>
          <td>0.075433</td>
          <td>0.642076</td>
          <td>3871</td>
        </tr>
        <tr>
          <th>Male</th>
          <td>0.271235</td>
          <td>0.692069</td>
          <td>8653</td>
        </tr>
      </tbody>
    </table>
    </div>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 444-448

Las agregaciones aún se realizan en todos los subgrupos para cada métrica,
para que cada uno continúe reduciéndose a un solo valor. Si miramos
`` group_min()``, vemos que violamos el mandato que especificamos para
`` fbeta_score()`` sugerido arriba (para mujeres con una raza de 'Otro'):

.. GENERATED FROM PYTHON SOURCE LINES 448-451

.. code-block:: default


    grouped_on_race_and_sex.group_min()





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none


    selection_rate    0.032258
    fbeta_06          0.503704
    count                  254
    dtype: object



.. GENERATED FROM PYTHON SOURCE LINES 452-455

Mirando el método ``ratio()``, vemos que la disparidad es peor
(específicamente entre hombres blancos y mujeres negras, si revisamos
la tabla ``by_group``):

.. GENERATED FROM PYTHON SOURCE LINES 455-458

.. code-block:: default


    grouped_on_race_and_sex.ratio(method="between_groups")





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none


    selection_rate     0.11893
    fbeta_06          0.690978
    count             0.029354
    dtype: object



.. GENERATED FROM PYTHON SOURCE LINES 459-473

Funciones de control
====================

Hay otra forma en que podemos dividir nuestros datos. Tenemos (*completamente
inventadas*) características para los puntajes crediticios de las personas (en tres rangos)
y también el tamaño del préstamo solicitado (grande o pequeño). En el escenario de préstamo,
es aceptable que las personas con puntajes crediticios altos
sean seleccionadas con más frecuencia que las personas con puntajes crediticios bajos.
Sin embargo, dentro de cada rango de puntaje crediticio, no queremos una disparidad
entre (digamos) mujeres negras y hombres blancos. Para ejemplificar estos casos,
tenemos el concepto de *funciones de control*.

Las funciones de control son introducidas por el argumento ``control_features =``
del objeto :class:`fairlearn.metrics.MetricFrame`:

.. GENERATED FROM PYTHON SOURCE LINES 473-482

.. code-block:: default


    cond_credit_score = MetricFrame(
        metrics=metric_fns,
        y_true=y_test,
        y_pred=y_pred,
        sensitive_features=A_test[["race", "sex"]],
        control_features=A_test["Credit Score"]
    )








.. GENERATED FROM PYTHON SOURCE LINES 483-486

Esto tiene un efecto inmediato en la propiedad ``overall``. En lugar
de tener un valor para cada métrica, ahora tenemos un valor para cada
valor único de la función de control:

.. GENERATED FROM PYTHON SOURCE LINES 486-489

.. code-block:: default


    cond_credit_score.overall






.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <div>
    <style scoped>
        .dataframe tbody tr th:only-of-type {
            vertical-align: middle;
        }

        .dataframe tbody tr th {
            vertical-align: top;
        }

        .dataframe thead th {
            text-align: right;
        }
    </style>
    <table border="1" class="dataframe">
      <thead>
        <tr style="text-align: right;">
          <th></th>
          <th>selection_rate</th>
          <th>fbeta_06</th>
          <th>count</th>
        </tr>
        <tr>
          <th>Credit Score</th>
          <th></th>
          <th></th>
          <th></th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <th>High</th>
          <td>0.03617</td>
          <td>0.664928</td>
          <td>470</td>
        </tr>
        <tr>
          <th>Low</th>
          <td>0.022924</td>
          <td>0.549994</td>
          <td>7285</td>
        </tr>
        <tr>
          <th>Medium</th>
          <td>0.386924</td>
          <td>0.695034</td>
          <td>6898</td>
        </tr>
      </tbody>
    </table>
    </div>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 490-491

La propiedad ``by_group`` es demostrada de manera similar:

.. GENERATED FROM PYTHON SOURCE LINES 491-493

.. code-block:: default

    cond_credit_score.by_group






.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <div>
    <style scoped>
        .dataframe tbody tr th:only-of-type {
            vertical-align: middle;
        }

        .dataframe tbody tr th {
            vertical-align: top;
        }

        .dataframe thead th {
            text-align: right;
        }
    </style>
    <table border="1" class="dataframe">
      <thead>
        <tr style="text-align: right;">
          <th></th>
          <th></th>
          <th></th>
          <th>selection_rate</th>
          <th>fbeta_06</th>
          <th>count</th>
        </tr>
        <tr>
          <th>Credit Score</th>
          <th>race</th>
          <th>sex</th>
          <th></th>
          <th></th>
          <th></th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <th rowspan="6" valign="top">High</th>
          <th rowspan="2" valign="top">Black</th>
          <th>Female</th>
          <td>0.0</td>
          <td>0.0</td>
          <td>54</td>
        </tr>
        <tr>
          <th>Male</th>
          <td>0.066667</td>
          <td>1.0</td>
          <td>15</td>
        </tr>
        <tr>
          <th rowspan="2" valign="top">Other</th>
          <th>Female</th>
          <td>0.0</td>
          <td>1.0</td>
          <td>21</td>
        </tr>
        <tr>
          <th>Male</th>
          <td>0.0</td>
          <td>1.0</td>
          <td>4</td>
        </tr>
        <tr>
          <th rowspan="2" valign="top">White</th>
          <th>Female</th>
          <td>0.019608</td>
          <td>0.529595</td>
          <td>306</td>
        </tr>
        <tr>
          <th>Male</th>
          <td>0.142857</td>
          <td>0.759305</td>
          <td>70</td>
        </tr>
        <tr>
          <th rowspan="6" valign="top">Low</th>
          <th rowspan="2" valign="top">Black</th>
          <th>Female</th>
          <td>0.00703</td>
          <td>0.626728</td>
          <td>569</td>
        </tr>
        <tr>
          <th>Male</th>
          <td>0.020513</td>
          <td>0.563536</td>
          <td>390</td>
        </tr>
        <tr>
          <th rowspan="2" valign="top">Other</th>
          <th>Female</th>
          <td>0.012048</td>
          <td>0.519084</td>
          <td>166</td>
        </tr>
        <tr>
          <th>Male</th>
          <td>0.037267</td>
          <td>0.693878</td>
          <td>161</td>
        </tr>
        <tr>
          <th rowspan="2" valign="top">White</th>
          <th>Female</th>
          <td>0.015084</td>
          <td>0.525773</td>
          <td>2917</td>
        </tr>
        <tr>
          <th>Male</th>
          <td>0.03342</td>
          <td>0.55025</td>
          <td>3082</td>
        </tr>
        <tr>
          <th rowspan="6" valign="top">Medium</th>
          <th rowspan="2" valign="top">Black</th>
          <th>Female</th>
          <td>0.211111</td>
          <td>0.639653</td>
          <td>90</td>
        </tr>
        <tr>
          <th>Male</th>
          <td>0.206897</td>
          <td>0.577576</td>
          <td>319</td>
        </tr>
        <tr>
          <th rowspan="2" valign="top">Other</th>
          <th>Female</th>
          <td>0.238806</td>
          <td>0.5</td>
          <td>67</td>
        </tr>
        <tr>
          <th>Male</th>
          <td>0.336996</td>
          <td>0.732057</td>
          <td>273</td>
        </tr>
        <tr>
          <th rowspan="2" valign="top">White</th>
          <th>Female</th>
          <td>0.373457</td>
          <td>0.680881</td>
          <td>648</td>
        </tr>
        <tr>
          <th>Male</th>
          <td>0.406108</td>
          <td>0.700837</td>
          <td>5501</td>
        </tr>
      </tbody>
    </table>
    </div>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 494-496

Los agregados de datos también se evalúan una vez para cada grupo identificado
por la función de control:

.. GENERATED FROM PYTHON SOURCE LINES 496-499

.. code-block:: default


    cond_credit_score.group_min()






.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <div>
    <style scoped>
        .dataframe tbody tr th:only-of-type {
            vertical-align: middle;
        }

        .dataframe tbody tr th {
            vertical-align: top;
        }

        .dataframe thead th {
            text-align: right;
        }
    </style>
    <table border="1" class="dataframe">
      <thead>
        <tr style="text-align: right;">
          <th></th>
          <th>selection_rate</th>
          <th>fbeta_06</th>
          <th>count</th>
        </tr>
        <tr>
          <th>Credit Score</th>
          <th></th>
          <th></th>
          <th></th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <th>High</th>
          <td>0.000000</td>
          <td>0.000000</td>
          <td>4.0</td>
        </tr>
        <tr>
          <th>Low</th>
          <td>0.007030</td>
          <td>0.519084</td>
          <td>161.0</td>
        </tr>
        <tr>
          <th>Medium</th>
          <td>0.206897</td>
          <td>0.500000</td>
          <td>67.0</td>
        </tr>
      </tbody>
    </table>
    </div>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 500-501

Y:

.. GENERATED FROM PYTHON SOURCE LINES 501-503

.. code-block:: default

    cond_credit_score.ratio(method="between_groups")






.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <div>
    <style scoped>
        .dataframe tbody tr th:only-of-type {
            vertical-align: middle;
        }

        .dataframe tbody tr th {
            vertical-align: top;
        }

        .dataframe thead th {
            text-align: right;
        }
    </style>
    <table border="1" class="dataframe">
      <thead>
        <tr style="text-align: right;">
          <th></th>
          <th>selection_rate</th>
          <th>fbeta_06</th>
          <th>count</th>
        </tr>
        <tr>
          <th>Credit Score</th>
          <th></th>
          <th></th>
          <th></th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <th>High</th>
          <td>0.000000</td>
          <td>0.000000</td>
          <td>0.013072</td>
        </tr>
        <tr>
          <th>Low</th>
          <td>0.188635</td>
          <td>0.748092</td>
          <td>0.052239</td>
        </tr>
        <tr>
          <th>Medium</th>
          <td>0.509462</td>
          <td>0.683007</td>
          <td>0.012180</td>
        </tr>
      </tbody>
    </table>
    </div>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 504-509

En nuestros datos, vemos que tenemos una escasez de resultados positivos
para aquellos que no blancos y que tienen altos ingresos, lo que afecta significativamente
los agregados de datos.

Podemos seguir agregando más funciones de control:

.. GENERATED FROM PYTHON SOURCE LINES 509-517

.. code-block:: default

    cond_both = MetricFrame(
        metrics=metric_fns,
        y_true=y_test,
        y_pred=y_pred,
        sensitive_features=A_test[["race", "sex"]],
        control_features=A_test[["Loan Size", "Credit Score"]]
    )





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    Found 36 subgroups. Evaluation may be slow




.. GENERATED FROM PYTHON SOURCE LINES 518-519

La propiedad ``overall`` se desglosa en más valores:

.. GENERATED FROM PYTHON SOURCE LINES 519-521

.. code-block:: default

    cond_both.overall






.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <div>
    <style scoped>
        .dataframe tbody tr th:only-of-type {
            vertical-align: middle;
        }

        .dataframe tbody tr th {
            vertical-align: top;
        }

        .dataframe thead th {
            text-align: right;
        }
    </style>
    <table border="1" class="dataframe">
      <thead>
        <tr style="text-align: right;">
          <th></th>
          <th></th>
          <th>selection_rate</th>
          <th>fbeta_06</th>
          <th>count</th>
        </tr>
        <tr>
          <th>Loan Size</th>
          <th>Credit Score</th>
          <th></th>
          <th></th>
          <th></th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <th rowspan="3" valign="top">Large</th>
          <th>High</th>
          <td>0.0</td>
          <td>1.0</td>
          <td>23</td>
        </tr>
        <tr>
          <th>Low</th>
          <td>0.004348</td>
          <td>0.60177</td>
          <td>460</td>
        </tr>
        <tr>
          <th>Medium</th>
          <td>0.071429</td>
          <td>0.388325</td>
          <td>434</td>
        </tr>
        <tr>
          <th rowspan="3" valign="top">Small</th>
          <th>High</th>
          <td>0.038031</td>
          <td>0.664928</td>
          <td>447</td>
        </tr>
        <tr>
          <th>Low</th>
          <td>0.024176</td>
          <td>0.549299</td>
          <td>6825</td>
        </tr>
        <tr>
          <th>Medium</th>
          <td>0.408106</td>
          <td>0.700288</td>
          <td>6464</td>
        </tr>
      </tbody>
    </table>
    </div>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 522-524

Al igual que la propiedad ``by_groups``, donde los valores ``NaN``
indica que no había muestras en la celda:

.. GENERATED FROM PYTHON SOURCE LINES 524-527

.. code-block:: default


    cond_both.by_group






.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <div>
    <style scoped>
        .dataframe tbody tr th:only-of-type {
            vertical-align: middle;
        }

        .dataframe tbody tr th {
            vertical-align: top;
        }

        .dataframe thead th {
            text-align: right;
        }
    </style>
    <table border="1" class="dataframe">
      <thead>
        <tr style="text-align: right;">
          <th></th>
          <th></th>
          <th></th>
          <th></th>
          <th>selection_rate</th>
          <th>fbeta_06</th>
          <th>count</th>
        </tr>
        <tr>
          <th>Loan Size</th>
          <th>Credit Score</th>
          <th>race</th>
          <th>sex</th>
          <th></th>
          <th></th>
          <th></th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <th rowspan="18" valign="top">Large</th>
          <th rowspan="6" valign="top">High</th>
          <th rowspan="2" valign="top">Black</th>
          <th>Female</th>
          <td>0.0</td>
          <td>1.0</td>
          <td>5</td>
        </tr>
        <tr>
          <th>Male</th>
          <td>0.0</td>
          <td>1.0</td>
          <td>1</td>
        </tr>
        <tr>
          <th rowspan="2" valign="top">Other</th>
          <th>Female</th>
          <td>0.0</td>
          <td>1.0</td>
          <td>3</td>
        </tr>
        <tr>
          <th>Male</th>
          <td>NaN</td>
          <td>NaN</td>
          <td>NaN</td>
        </tr>
        <tr>
          <th rowspan="2" valign="top">White</th>
          <th>Female</th>
          <td>0.0</td>
          <td>1.0</td>
          <td>13</td>
        </tr>
        <tr>
          <th>Male</th>
          <td>0.0</td>
          <td>1.0</td>
          <td>1</td>
        </tr>
        <tr>
          <th rowspan="6" valign="top">Low</th>
          <th rowspan="2" valign="top">Black</th>
          <th>Female</th>
          <td>0.0</td>
          <td>1.0</td>
          <td>52</td>
        </tr>
        <tr>
          <th>Male</th>
          <td>0.030303</td>
          <td>1.0</td>
          <td>33</td>
        </tr>
        <tr>
          <th rowspan="2" valign="top">Other</th>
          <th>Female</th>
          <td>0.0</td>
          <td>1.0</td>
          <td>3</td>
        </tr>
        <tr>
          <th>Male</th>
          <td>0.0</td>
          <td>0.0</td>
          <td>14</td>
        </tr>
        <tr>
          <th rowspan="2" valign="top">White</th>
          <th>Female</th>
          <td>0.0</td>
          <td>0.0</td>
          <td>133</td>
        </tr>
        <tr>
          <th>Male</th>
          <td>0.004444</td>
          <td>0.557377</td>
          <td>225</td>
        </tr>
        <tr>
          <th rowspan="6" valign="top">Medium</th>
          <th rowspan="2" valign="top">Black</th>
          <th>Female</th>
          <td>0.0</td>
          <td>0.0</td>
          <td>7</td>
        </tr>
        <tr>
          <th>Male</th>
          <td>0.026316</td>
          <td>0.295652</td>
          <td>38</td>
        </tr>
        <tr>
          <th rowspan="2" valign="top">Other</th>
          <th>Female</th>
          <td>0.111111</td>
          <td>0.0</td>
          <td>9</td>
        </tr>
        <tr>
          <th>Male</th>
          <td>0.0</td>
          <td>0.0</td>
          <td>19</td>
        </tr>
        <tr>
          <th rowspan="2" valign="top">White</th>
          <th>Female</th>
          <td>0.0</td>
          <td>0.0</td>
          <td>28</td>
        </tr>
        <tr>
          <th>Male</th>
          <td>0.087087</td>
          <td>0.420976</td>
          <td>333</td>
        </tr>
        <tr>
          <th rowspan="18" valign="top">Small</th>
          <th rowspan="6" valign="top">High</th>
          <th rowspan="2" valign="top">Black</th>
          <th>Female</th>
          <td>0.0</td>
          <td>0.0</td>
          <td>49</td>
        </tr>
        <tr>
          <th>Male</th>
          <td>0.071429</td>
          <td>1.0</td>
          <td>14</td>
        </tr>
        <tr>
          <th rowspan="2" valign="top">Other</th>
          <th>Female</th>
          <td>0.0</td>
          <td>1.0</td>
          <td>18</td>
        </tr>
        <tr>
          <th>Male</th>
          <td>0.0</td>
          <td>1.0</td>
          <td>4</td>
        </tr>
        <tr>
          <th rowspan="2" valign="top">White</th>
          <th>Female</th>
          <td>0.020478</td>
          <td>0.529595</td>
          <td>293</td>
        </tr>
        <tr>
          <th>Male</th>
          <td>0.144928</td>
          <td>0.759305</td>
          <td>69</td>
        </tr>
        <tr>
          <th rowspan="6" valign="top">Low</th>
          <th rowspan="2" valign="top">Black</th>
          <th>Female</th>
          <td>0.007737</td>
          <td>0.626728</td>
          <td>517</td>
        </tr>
        <tr>
          <th>Male</th>
          <td>0.019608</td>
          <td>0.518293</td>
          <td>357</td>
        </tr>
        <tr>
          <th rowspan="2" valign="top">Other</th>
          <th>Female</th>
          <td>0.01227</td>
          <td>0.519084</td>
          <td>163</td>
        </tr>
        <tr>
          <th>Male</th>
          <td>0.040816</td>
          <td>0.715789</td>
          <td>147</td>
        </tr>
        <tr>
          <th rowspan="2" valign="top">White</th>
          <th>Female</th>
          <td>0.015805</td>
          <td>0.527656</td>
          <td>2784</td>
        </tr>
        <tr>
          <th>Male</th>
          <td>0.035702</td>
          <td>0.550162</td>
          <td>2857</td>
        </tr>
        <tr>
          <th rowspan="6" valign="top">Medium</th>
          <th rowspan="2" valign="top">Black</th>
          <th>Female</th>
          <td>0.228916</td>
          <td>0.648094</td>
          <td>83</td>
        </tr>
        <tr>
          <th>Male</th>
          <td>0.231317</td>
          <td>0.590371</td>
          <td>281</td>
        </tr>
        <tr>
          <th rowspan="2" valign="top">Other</th>
          <th>Female</th>
          <td>0.258621</td>
          <td>0.524085</td>
          <td>58</td>
        </tr>
        <tr>
          <th>Male</th>
          <td>0.362205</td>
          <td>0.740024</td>
          <td>254</td>
        </tr>
        <tr>
          <th rowspan="2" valign="top">White</th>
          <th>Female</th>
          <td>0.390323</td>
          <td>0.682328</td>
          <td>620</td>
        </tr>
        <tr>
          <th>Male</th>
          <td>0.426664</td>
          <td>0.705861</td>
          <td>5168</td>
        </tr>
      </tbody>
    </table>
    </div>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 528-530

Los agregados de datos se comportan de manera similar. A estas alturas, estamos teniendo problemas importantes
con intersecciones poco pobladas. Consideremos:

.. GENERATED FROM PYTHON SOURCE LINES 530-547

.. code-block:: default



    def member_counts(y_true, y_pred):
        assert len(y_true) == len(y_pred)
        return len(y_true)


    counts = MetricFrame(
        metrics=member_counts,
        y_true=y_test,
        y_pred=y_pred,
        sensitive_features=A_test[["race", "sex"]],
        control_features=A_test[["Loan Size", "Credit Score"]]
    )

    counts.by_group





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    Found 36 subgroups. Evaluation may be slow

    Loan Size  Credit Score  race   sex   
    Large      High          Black  Female       5
                                    Male         1
                             Other  Female       3
                                    Male       NaN
                             White  Female      13
                                    Male         1
               Low           Black  Female      52
                                    Male        33
                             Other  Female       3
                                    Male        14
                             White  Female     133
                                    Male       225
               Medium        Black  Female       7
                                    Male        38
                             Other  Female       9
                                    Male        19
                             White  Female      28
                                    Male       333
    Small      High          Black  Female      49
                                    Male        14
                             Other  Female      18
                                    Male         4
                             White  Female     293
                                    Male        69
               Low           Black  Female     517
                                    Male       357
                             Other  Female     163
                                    Male       147
                             White  Female    2784
                                    Male      2857
               Medium        Black  Female      83
                                    Male       281
                             Other  Female      58
                                    Male       254
                             White  Female     620
                                    Male      5168
    Name: member_counts, dtype: object



.. GENERATED FROM PYTHON SOURCE LINES 548-550

Recordemos que ``NaN`` indica que no hubo individuos
en una celda - ``member_counts()`` ni siquiera habrá sido llamado.

.. GENERATED FROM PYTHON SOURCE LINES 552-561

Exportando desde MetricFrame
============================

A veces, necesitamos extraer nuestros datos para usarlos en otras herramientas.
Para esto, podemos usar el método :py:meth:`pandas.DataFrame.to_csv`,
ya que :py:meth:`~fairlearn.metrics.MetricFrame.by_group`
será de tipo :class:`pandas.DataFrame` (o en algunos casos, será
de tipo :class:`pandas.Series`, pero tiene un método similar
:py:meth:`~ pandas.Series.to_csv`):

.. GENERATED FROM PYTHON SOURCE LINES 561-565

.. code-block:: default


    csv_output = cond_credit_score.by_group.to_csv()
    print(csv_output)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    Credit Score,race,sex,selection_rate,fbeta_06,count
    High,Black,Female,0.0,0.0,54
    High,Black,Male,0.06666666666666667,1.0,15
    High,Other,Female,0.0,1.0,21
    High,Other,Male,0.0,1.0,4
    High,White,Female,0.0196078431372549,0.5295950155763239,306
    High,White,Male,0.14285714285714285,0.7593052109181142,70
    Low,Black,Female,0.007029876977152899,0.6267281105990783,569
    Low,Black,Male,0.020512820512820513,0.56353591160221,390
    Low,Other,Female,0.012048192771084338,0.5190839694656488,166
    Low,Other,Male,0.037267080745341616,0.6938775510204082,161
    Low,White,Female,0.015083990401097017,0.5257731958762887,2917
    Low,White,Male,0.033419857235561325,0.5502497502497502,3082
    Medium,Black,Female,0.2111111111111111,0.6396526772793053,90
    Medium,Black,Male,0.20689655172413793,0.5775764439411097,319
    Medium,Other,Female,0.23880597014925373,0.5,67
    Medium,Other,Male,0.336996336996337,0.7320574162679426,273
    Medium,White,Female,0.3734567901234568,0.6808811402992107,648
    Medium,White,Male,0.40610798036720597,0.700837357443748,5501





.. GENERATED FROM PYTHON SOURCE LINES 566-573

El método :py:meth:`pandas.DataFrame.to_csv` tiene una gran cantidad de
argumentos para controlar el CSV exportado. Por ejemplo, puede escribir
directamente a un archivo CSV, en lugar de devolver una cadena de caracteres (como se
mostró anteriormente).

La propiedad :meth:`~ fairlearn.metrics.MetricFrame.overall` puede
manejarse de manera similar, en los casos en que no sea un escalar.


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 0 minutes  13.179 seconds)


.. _sphx_glr_download_auto_examples_plot_new_metrics.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example



  .. container:: sphx-glr-download sphx-glr-download-python

     :download:`Download Python source code: plot_new_metrics.py <plot_new_metrics.py>`



  .. container:: sphx-glr-download sphx-glr-download-jupyter

     :download:`Download Jupyter notebook: plot_new_metrics.ipynb <plot_new_metrics.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
