{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "GridSearch con datos de censo\n=============================\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Este notebook muestra c\u00f3mo usar Fairlearn para generar predictores para\nel conjunto de datos del censo. Este conjunto de datos es un problema de\nclasificaci\u00f3n: dado un rango de datos sobre 32.000 personas, predecir si\nsus ingresos anuales est\u00e1n por encima o por debajo de cincuenta mil\nd\u00f3lares por a\u00f1o.\n\nPara los prop\u00f3sitos de este notebook, trataremos esto como un problema\nde decisi\u00f3n de pr\u00e9stamo. Fingiremos que la etiqueta indica si cada\nindividuo pag\u00f3 o no un pr\u00e9stamo en el pasado. Usaremos los datos para\nentrenar un predictor para predecir si individuos no vistos previamente\npagar\u00e1 un pr\u00e9stamo o no. El supuesto es que las predicciones del modelo\nse utilizan para decidir si un individuo se le debe ofrecer un pr\u00e9stamo.\n\nPrimero entrenaremos a un predictor inconsciente de la equidad y\ndemostraremos que conduce a decisiones bajo una noci\u00f3n espec\u00edfica de\nequidad llamada *paridad demogr\u00e1fica*. Luego mitigamos la injusticia\naplicando el :c\u00f3digo:algoritmo [GridSearch]{.title-ref} del Paquete\nFairlearn.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Cargar y preprocesar el conjunto de datos\n\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\--Descargamos\nel conjunto de datos usando la funci\u00f3n [fetch\\_adult]{.title-ref} en\n[fairlearn.datasets]{.title-ref}. Empezamos importando los distintos\nm\u00f3dulos que vamos a utilizar:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\nfrom fairlearn.reductions import GridSearch\nfrom fairlearn.reductions import DemographicParity, ErrorRate\nfrom fairlearn.metrics import MetricFrame, selection_rate, count\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import metrics as skm\nimport pandas as pd\nimport matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can now load and inspect the data by using the\n[fairlearn.datasets]{.title-ref} module:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_openml\n\ndata = fetch_openml(data_id=1590, as_frame=True)\nX_raw = data.data\nY = (data.target == '>50K') * 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Vamos a tratar el sexo de cada individuo como un sensible caracter\u00edstica\n(donde 0 indica mujer y 1 indica hombre), y en En este caso particular,\nvamos a separar esta funci\u00f3n y la eliminaremos. de los datos\nprincipales. Luego realizamos algunos pasos est\u00e1ndar de preprocesamiento\nde datos para convertir el datos en un formato adecuado para los\nalgoritmos aprendizaje autom\u00e1tico\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "A = X_raw[\"sex\"]\nX = X_raw.drop(labels=['sex'], axis=1)\nX = pd.get_dummies(X)\n\nsc = StandardScaler()\nX_scaled = sc.fit_transform(X)\nX_scaled = pd.DataFrame(X_scaled, columns=X.columns)\n\nle = LabelEncoder()\nY = le.fit_transform(Y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finalmente, dividimos los datos en conjuntos de entrenamiento y prueba:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "X_train, X_test, Y_train, Y_test, A_train, A_test = train_test_split(X_scaled,\n                                                                     Y,\n                                                                     A,\n                                                                     test_size=0.2,\n                                                                     random_state=0,\n                                                                     stratify=Y)\n\n# Work around indexing bug\nX_train = X_train.reset_index(drop=True)\nA_train = A_train.reset_index(drop=True)\nX_test = X_test.reset_index(drop=True)\nA_test = A_test.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Entrenando a un predictor inconsciente de la equidad\n\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\--\n\nPara mostrar el efecto de Fairlearn, primero entrenaremos un predictor\nde aprendizaje autom\u00e1tico est\u00e1ndar que no incorpora justicia. Para\nvelocidad de demostraci\u00f3n, usamos\n`sklearn.linear_model.LogisticRegression`{.interpreted-text\nrole=\"class\"} class:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "unmitigated_predictor = LogisticRegression(solver='liblinear', fit_intercept=True)\n\nunmitigated_predictor.fit(X_train, Y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Podemos comenzar a evaluar la equidad del predictor usando el\n\\`MetricFrame\\`:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "metric_frame = MetricFrame(metrics={\"accuracy\": skm.accuracy_score,\n                                    \"selection_rate\": selection_rate,\n                                    \"count\": count},\n                           sensitive_features=A_test,\n                           y_true=Y_test,\n                           y_pred=unmitigated_predictor.predict(X_test))\nprint(metric_frame.overall)\nprint(metric_frame.by_group)\nmetric_frame.by_group.plot.bar(\n    subplots=True, layout=[3, 1], legend=False, figsize=[12, 8],\n    title='Accuracy and selection rate by group')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Al observar la disparidad en la precisi\u00f3n, vemos que los hombres tienen\nun error aproximadamente tres veces mayor que las mujeres. M\u00e1s\ninteresante es la disparidad de oportunidades: a los hombres se les\nofrecen pr\u00e9stamos tres veces la tasa de mujeres.\n\nA pesar de que eliminamos la funci\u00f3n de los datos de entrenamiento,\nnuestro predictor a\u00fan discrimina seg\u00fan el sexo. Esto demuestra que\nsimplemente ignorar una caracter\u00edstica sensible al instalar un predictor\nrara vez elimina la injusticia. En general, habr\u00e1 suficientes otras\ncaracter\u00edsticas correlacionadas con la eliminaci\u00f3n caracter\u00edstica para\ngenerar un impacto dispar.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Mitigaci\u00f3n con GridSearch\n=========================\n\nLa clase `fairlearn.reductions.GridSearch`{.interpreted-text\nrole=\"class\"} implementa una versi\u00f3n simplificada de reducci\u00f3n\nexponencial del gradiente de [Agarwal et al.\n2018](https://arxiv.org/abs/1803.02453). El usuario proporciona un\nestimador de aprendizaje autom\u00e1tico est\u00e1ndar, que se trata como una caja\nnegra. [GridSearch]{.title-ref} funciona generando una secuencia de\nreetiquetas y reponderaciones, y entrena un predictor para cada uno.\n\nPara este ejemplo, especificamos la paridad demogr\u00e1fica (en la\ncaracter\u00edstica sensible del sexo) como la m\u00e9trica de equidad. La paridad\ndemogr\u00e1fica requiere que se ofrezca la oportunidad a las personas (est\u00e9n\naprobadas para un pr\u00e9stamo en este ejemplo) independientemente de la\nmembres\u00eda en la clase sensible (es decir, a mujeres y a hombres se les\ndebe ofrecer pr\u00e9stamos a la misma tasa). Estamos usando esta m\u00e9trica por\nsimplicidad; en general, la equidad adecuada m\u00e9trica no ser\u00e1 obvia.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sweep = GridSearch(LogisticRegression(solver='liblinear', fit_intercept=True),\n                   constraints=DemographicParity(),\n                   grid_size=71)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Nuestros algoritmos proporcionan m\u00e9todos `fit ()`{.sourceCode} y\n`predict()`{.sourceCode}, por lo que se comportan de manera similar a\notros paquetes ML en Python. Sin embargo, tenemos que especificar dos\nargumentos adicionales para: c\u00f3digo: [fit ()]{.title-ref} - la columna\nde sensibles etiquetas de caracter\u00edsticas, y tambi\u00e9n la cantidad de\npredictores que se generar\u00e1n en nuestro barrido.\n\nDespu\u00e9s de que se complete `fit ()`{.sourceCode}, extraemos el conjunto\ncompleto de predictores del objeto\n`fairlearn.reductions.GridSearch`{.interpreted-text role=\"class\"}.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sweep.fit(X_train, Y_train,\n          sensitive_features=A_train)\n\npredictors = sweep.predictors_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Podr\u00edamos trazar m\u00e9tricas de rendimiento y equidad de estos predictores\nahora. Sin embargo, la gr\u00e1fica ser\u00eda algo confusa debido a la cantidad\nde modelos. En este caso, vamos a eliminar los predictores que est\u00e1n\ndominados en el espacio de error-disparidad por otros del barrido (tenga\nen cuenta que la disparidad solo ser\u00e1 calculado para la caracter\u00edstica\nsensible; otras caracter\u00edsticas potencialmente sensibles no ser\nmitigado). En general, es posible que no desee hacer esto, ya que puede\nhaber otras consideraciones m\u00e1s all\u00e1 de la optimizaci\u00f3n estricta del\nerror y la disparidad (de la caracter\u00edstica sensible dada).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "errors, disparities = [], []\nfor m in predictors:\n    def classifier(X): return m.predict(X)\n\n\n    error = ErrorRate()\n    error.load_data(X_train, pd.Series(Y_train), sensitive_features=A_train)\n    disparity = DemographicParity()\n    disparity.load_data(X_train, pd.Series(Y_train), sensitive_features=A_train)\n\n    errors.append(error.gamma(classifier)[0])\n    disparities.append(disparity.gamma(classifier).max())\n\nall_results = pd.DataFrame({\"predictor\": predictors, \"error\": errors, \"disparity\": disparities})\n\nnon_dominated = []\nfor row in all_results.itertuples():\n    errors_for_lower_or_eq_disparity = all_results[\"error\"][all_results[\"disparity\"] <= row.disparity]\n    if row.error <= errors_for_lower_or_eq_disparity.min():\n        non_dominated.append(row.predictor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finalmente, podemos evaluar los modelos dominantes junto con el modelo\nno mitigado.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "predictions = {\"unmitigated\": unmitigated_predictor.predict(X_test)}\nmetric_frames = {\"unmitigated\": metric_frame}\nfor i in range(len(non_dominated)):\n    key = \"dominant_model_{0}\".format(i)\n    predictions[key] = non_dominated[i].predict(X_test)\n\n    metric_frames[key] = MetricFrame(metrics={\"accuracy\": skm.accuracy_score,\n                                              \"selection_rate\": selection_rate,\n                                              \"count\": count},\n                                     sensitive_features=A_test,\n                                     y_true=Y_test,\n                                     y_pred=predictions[key])\n\n\nx = [metric_frame.overall['accuracy'] for metric_frame in metric_frames.values()]\ny = [metric_frame.difference()['selection_rate'] for metric_frame in metric_frames.values()]\nkeys = list(metric_frames.keys())\nplt.scatter(x, y)\nfor i in range(len(x)):\n    plt.annotate(keys[i], (x[i] + 0.0003, y[i]))\nplt.xlabel(\"accuracy\")\nplt.ylabel(\"selection rate difference\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Vemos la formaci\u00f3n de un frente de Pareto: el conjunto de predictores\nque representan compensaciones \u00f3ptimas entre precisi\u00f3n y disparidad en\nlas predicciones. En el caso ideal, tendr\u00edamos un predictor en (1,0) -\nperfectamente preciso y sin cualquier injusticia bajo paridad\ndemogr\u00e1fica (con respecto a la caracter\u00edstica sensible \\\"sexo\\\"). El\nfrente de Pareto representa lo m\u00e1s cerca que podemos llegar a este ideal\nseg\u00fan nuestros datos y elecci\u00f3n de estimador. Tenga en cuenta el rango\nde los ejes: el eje de disparidad cubre m\u00e1s valores que la precisi\u00f3n,\npara que podamos reducir la disparidad sustancialmente por una peque\u00f1a\np\u00e9rdida de precisi\u00f3n. En un ejemplo real, elegir\u00edamos el modelo que\nrepresentara la mejor compensaci\u00f3n entre precisi\u00f3n y disparidad dadas\nlas limitaciones comerciales relevantes.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}