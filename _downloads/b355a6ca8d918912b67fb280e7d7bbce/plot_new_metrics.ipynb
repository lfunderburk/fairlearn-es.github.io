{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "M\u00e9tricas con m\u00faltiples funciones\n================================\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Este notebook muestra la nueva API para m\u00e9tricas, que admite m\u00faltiples\ncaracter\u00edsticas sensibles y condicionales. Este ejemplo no contiene una\ndiscusi\u00f3n adecuada sobre c\u00f3mo la justicia se relaciona con el conjunto\nde datos utilizado, aunque resalta problemas que los usuarios pueden\nquerer considere al analizar sus conjuntos de datos.\n\nVamos a considerar un escenario de pr\u00e9stamo de cr\u00e9dito, suponiendo que\ntengamos un modelo que predice si un cliente en particular va a\nreembolsar un pr\u00e9stamo. Esto podr\u00eda utilizarse como base para decidir si\no no ofrecer un pr\u00e9stamo a ese cliente. Con m\u00e9tricas tradicionales,\nevaluar\u00edamos el modelo usando:\n\n-   Los valores \\'verdaderos\\' del conjunto de prueba\n-   Las predicciones del modelo del conjunto de prueba\n\nNuestras m\u00e9tricas de equidad calculan estad\u00edsticas de equidad basadas en\ngrupos. Para usar estos, tambi\u00e9n necesitamos columnas categ\u00f3ricas del\nconjunto de prueba. Para este ejemplo, incluiremos:\n\n-   El sexo de cada individuo (dos valores \u00fanicos)\n-   La raza de cada individuo (tres valores \u00fanicos)\n-   La categor\u00eda de puntaje crediticio de cada individuo (tres valores\n    \u00fanicos)\n-   Si el pr\u00e9stamo se considera \\'grande\\' o \\'peque\u00f1o\\'\n\nEl sexo y la raza de una persona no deben afectar la decisi\u00f3n de un\npr\u00e9stamo, pero ser\u00eda leg\u00edtimo considerar el puntaje crediticio de una\npersona y el tama\u00f1o relativo del pr\u00e9stamo que deseaban.\n\nUn escenario real ser\u00e1 m\u00e1s complicado, pero esto servir\u00e1 para ilustrar\nel uso de las nuevas m\u00e9tricas.\n\nObteniendo los datos\n====================\n\n\\*Esta secci\u00f3n se puede omitir. Simplemente crea un conjunto de datos\npara fines ilustrativos\\*\n\nUtilizaremos el conocido conjunto de datos UCI \\'Adult\\' como base de\neste demostraci\u00f3n. Esto no es para un escenario de pr\u00e9stamos, pero\nconsideraremos como uno para los prop\u00f3sitos de este ejemplo. Usaremos el\nexistente columnas \\'raza\\' y \\'sexo\\' (recortando la primera a tres\nvalores \u00fanicos), y fabrique bandas de puntaje crediticio y tama\u00f1os de\npr\u00e9stamos a partir de otras columnas. Comenzamos con algunas\ndeclaraciones de \\`importaci\u00f3n\\`:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import functools\nimport numpy as np\n\nimport sklearn.metrics as skm\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.datasets import fetch_openml\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.compose import make_column_selector as selector\nfrom sklearn.pipeline import Pipeline\n\nfrom fairlearn.metrics import MetricFrame\nfrom fairlearn.metrics import selection_rate, count"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A continuaci\u00f3n, importamos los datos:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "data = fetch_openml(data_id=1590, as_frame=True)\nX_raw = data.data\ny = (data.target == \">50K\") * 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Para mayor claridad, consolidamos la columna \\'raza\\' para tener tres\nvalores \u00fanicos:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def race_transform(input_str):\n    \"\"\"Reduce values to White, Black and Other.\"\"\"\n    result = \"Other\"\n    if input_str == \"White\" or input_str == \"Black\":\n        result = input_str\n    return result\n\n\nX_raw[\"race\"] = (\n    X_raw[\"race\"].map(race_transform).fillna(\"Other\").astype(\"category\")\n)\nprint(np.unique(X_raw[\"race\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Despu\u00e9s, fabricamos las columnas para la banda de calificaci\u00f3n\ncrediticia y tama\u00f1o del pr\u00e9stamo solicitado. Estos est\u00e1n hipot\u00e9ticos, y\nno parte del conjunto de datos real de alguna manera. Son simplemente\npara fines ilustrativos.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def marriage_transform(m_s_string):\n    \"\"\"Perform some simple manipulations.\"\"\"\n    result = \"Low\"\n    if m_s_string.startswith(\"Married\"):\n        result = \"Medium\"\n    elif m_s_string.startswith(\"Widowed\"):\n        result = \"High\"\n    return result\n\n\ndef occupation_transform(occ_string):\n    \"\"\"Perform some simple manipulations.\"\"\"\n    result = \"Small\"\n    if occ_string.startswith(\"Machine\"):\n        result = \"Large\"\n    return result\n\n\ncol_credit = X_raw[\"marital-status\"].map(marriage_transform).fillna(\"Low\")\ncol_credit.name = \"Credit Score\"\ncol_loan_size = X_raw[\"occupation\"].map(occupation_transform).fillna(\"Small\")\ncol_loan_size.name = \"Loan Size\"\n\nA = X_raw[[\"race\", \"sex\"]]\nA[\"Credit Score\"] = col_credit\nA[\"Loan Size\"] = col_loan_size\nA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ahora que hemos importado nuestro conjunto de datos y fabricado algunas\nfunciones, podemos realizar un procesamiento m\u00e1s convencional. Para\nevitar el problema de [fuga de\ndatos](https://en.wikipedia.org/wiki/Leakage_%20(machine_learning)),\nnecesitamos dividir los datos en conjuntos de prueba y entrenamiento\nantes de aplicar cualquier transformaci\u00f3n o escala:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "(X_train, X_test, y_train, y_test, A_train, A_test) = train_test_split(\n    X_raw, y, A, test_size=0.3, random_state=54321, stratify=y\n)\n\n# Aseg\u00farese de que los \u00edndices est\u00e9n alineados entre X, y, A,\n# despu\u00e9s de seleccionar y dividir el marco de datos en Series.\n\nX_train = X_train.reset_index(drop=True)\nX_test = X_test.reset_index(drop=True)\ny_train = y_train.reset_index(drop=True)\ny_test = y_test.reset_index(drop=True)\nA_train = A_train.reset_index(drop=True)\nA_test = A_test.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A continuaci\u00f3n, construimos dos objetos\n`~ sklearn.pipeline.Pipeline`{.interpreted-text role=\"class\"} para\nprocesar las columnas, una para datos num\u00e9ricos y la otra para datos\ncateg\u00f3ricos. Ambos imputan valores perdidos; la diferencia es si los\ndatos est\u00e1n escalados (columnas num\u00e9ricas) o tienen codificaci\u00f3n one-hot\n(columnas categ\u00f3ricas). Imputaci\u00f3n de valores faltantes generalmente\ndeben hacerse con cuidado, ya que esto podr\u00eda introducir sesgos\npotencialmente. Por supuesto, eliminar filas con los datos faltantes\ntambi\u00e9n puede causar problemas, si subgrupos particulares tienen datos\nde peor calidad.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "numeric_transformer = Pipeline(\n    steps=[(\"impute\", SimpleImputer()), (\"scaler\", StandardScaler())]\n)\ncategorical_transformer = Pipeline(\n    [\n        (\"impute\", SimpleImputer(strategy=\"most_frequent\")),\n        (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\"))\n    ]\n)\npreprocessor = ColumnTransformer(\n    transformers=[\n        (\"num\", numeric_transformer, selector(dtype_exclude=\"category\")),\n        (\"cat\", categorical_transformer, selector(dtype_include=\"category\"))\n    ]\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Con nuestro preprocesador definido, ahora podemos construir un nueva\ncanalizaci\u00f3n que incluye un Estimador:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "unmitigated_predictor = Pipeline(\n    steps=[\n        (\"preprocessor\", preprocessor),\n        (\n            \"classifier\",\n            LogisticRegression(solver=\"liblinear\", fit_intercept=True)\n        )\n    ]\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Con la pipeline (tuber\u00eda) completamente definida, primero podemos\nentrenarla con los datos de entrenamiento y luego generar predicciones\nutilizando los datos de prueba.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "unmitigated_predictor.fit(X_train, y_train)\ny_pred = unmitigated_predictor.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Analizando el modelo con m\u00e9tricas ================================\n\nDespu\u00e9s del formateo de datos y entrenamiento de modelos, tenemos lo\nsiguiente de nuestro conjunto de prueba:\n\n-   Un vector de valores verdaderos llamado `y_test`\n-   Un vector de predicciones del modelo llamado `y_pred`\n-   Un DataFrame (tabla de datos) con caracter\u00edsticas categ\u00f3ricas\n    relevantes para la equidad llamado `A_test`\n\nSi fu\u00e9semos a utilizar un an\u00e1lisis de modelo tradicional, utilizar\u00edamos\nalgunas m\u00e9tricas que eval\u00faan el conjunto de datos completo. Supongamos\nque en este caso, las m\u00e9tricas relevantes son\n`fairlearn.metrics.selection_rate`{.interpreted-text role=\"func\"} y\n`sklearn.metrics.fbeta_score`{.interpreted-text role=\"func\"} (con [beta\n= 0.6]{.title-ref}\\`). Podemos evaluar estas m\u00e9tricas directamente:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"Selection Rate:\", selection_rate(y_test, y_pred))\nprint(\"fbeta:\", skm.fbeta_score(y_test, y_pred, beta=0.6))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Sabemos que hay caracter\u00edsticas sensibles en nuestros datos y queremos\nasegurarnos de no da\u00f1ar a las personas debido a su membres\u00eda en estos\ngrupos. Para este prop\u00f3sito, Fairlearn proporciona la clase\n`fairlearn.metrics.MetricFrame`{.interpreted-text role=\"clase\"}.\nConstruyamos una instancia de esta clase y luego miremos sus\ncapacidades:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fbeta_06 = functools.partial(skm.fbeta_score, beta=0.6, zero_division=1)\n\nmetric_fns = {\n    \"selection_rate\": selection_rate,\n    \"fbeta_06\": fbeta_06,\n    \"count\": count\n}\n\ngrouped_on_sex = MetricFrame(\n    metrics=metric_fns,\n    y_true=y_test,\n    y_pred=y_pred,\n    sensitive_features=A_test[\"sex\"]\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "La clase `fairlearn.metrics.MetricFrame`{.interpreted-text role=\"class\"}\nrequiere un m\u00ednimo de cuatro argumentos:\n\n1.  Las funciones m\u00e9tricas que se evaluar\u00e1n\n2.  Los valores verdaderos\n3.  Los valores predichos\n4.  Los valores de las caracter\u00edsticas sensibles\n\nTodos estos se pasan como argumentos al constructor. Si m\u00e1s de una\nm\u00e9trica se requiere(como en este caso), entonces debemos proporcionarlos\nen un diccionario.\n\nLas m\u00e9tricas deben tener una firma `fn (y_true, y_pred)`, entonces\ntenemos que usar `functools.partial`{.interpreted-text role=\"func\"} en\n`fbeta_score()` para proporcionar `beta = 0.6` (mostraremos c\u00f3mo pasar\nuna lista con argumentos como ponderaciones de muestra en breve).\n\nAhora echaremos un vistazo m\u00e1s de cerca a\n`fairlearn.metrics.MetricFrame`{.interpreted-text role=\"class\"}.\nPrimero, est\u00e1 la propiedad `overall`, que contiene las m\u00e9tricas\nevaluadas en el conjunto de datos completo. Vemos que esto contiene el\nmismos valores calculados anteriormente:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "assert grouped_on_sex.overall[\"selection_rate\"] == selection_rate(\n    y_test, y_pred\n)\nassert grouped_on_sex.overall[\"fbeta_06\"] == skm.fbeta_score(\n    y_test, y_pred, beta=0.6\n)\nprint(grouped_on_sex.overall)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "La otra propiedad en `fairlearn.metrics.MetricFrame`{.interpreted-text\nrole=\"class\"} es `by_group`, el cual contiene las m\u00e9tricas evaluadas en\ncada subgrupo definido por las categor\u00edas en el argumento\n`sensitive_features =`. Tenga en cuenta que\n`fairlearn.metrics.count`{.interpreted-text role=\"func\"} se puede usar\npara mostrar el n\u00famero de puntos de datos en cada subgrupo. En este\ncaso, tenemos resultados para hombres y mujeres:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "grouped_on_sex.by_group"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Podemos ver inmediatamente una disparidad sustancial en la tasa de\nselecci\u00f3n entre masculinos y femeninos.\n\nTambi\u00e9n podemos crear otro objeto\n`fairlearn.metrics.MetricFrame`{.interpreted-text role=\"class\"} usando\nla raza como caracter\u00edstica sensible:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "grouped_on_race = MetricFrame(\n    metrics=metric_fns,\n    y_true=y_test,\n    y_pred=y_pred,\n    sensitive_features=A_test[\"race\"]\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "La propiedad `overall` no cambia:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "assert (grouped_on_sex.overall == grouped_on_race.overall).all()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "La propiedad `by_group` ahora contiene las m\u00e9tricas evaluadas seg\u00fan la\ncolumna \\'raza\\':\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "grouped_on_race.by_group"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Vemos que tambi\u00e9n existe una disparidad significativa en las tasas de\nselecci\u00f3n cuando agrupaci\u00f3n por raza.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Muestras de pesos y otras matrices\n==================================\n\nObservamos anteriormente que las funciones m\u00e9tricas subyacentes pasaron\nal constructor `fairlearn.metrics.MetricFrame`{.interpreted-text\nrole=\"class\"} debe ser de la forma `fn (y_true, y_pred)` - no admitimos\nargumentos escalares como `pos_label =` o `beta =` en el constructor.\nDichos argumentos deben estar vinculados a una nueva funci\u00f3n usando\n`functools.partial`{.interpreted-text role=\"func\"}, junto con el\nresultado. Sin embargo, Fairlearn tambi\u00e9n apoya argumentos que tienen\nsolo un elemento por cada muestra, con una matriz de pesos de muestra es\nel ejemplo m\u00e1s com\u00fan. Estos est\u00e1n divididos en subgrupos junto con\n`y_true` y `y_pred`, y se pasan a la m\u00e9trica subyacente.\n\nPara usar estos argumentos, pasamos en un diccionario como\n`sample_params =` argumento del constructor. Generemos algunos pesos\naleatorios y p\u00e1sales estos:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "random_weights = np.random.rand(len(y_test))\n\nexample_sample_params = {\n    \"selection_rate\": {\"sample_weight\": random_weights},\n    \"fbeta_06\": {\"sample_weight\": random_weights}\n}\n\n\ngrouped_with_weights = MetricFrame(\n    metrics=metric_fns,\n    y_true=y_test,\n    y_pred=y_pred,\n    sensitive_features=A_test[\"sex\"],\n    sample_params=example_sample_params\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Podemos inspeccionar los valores generales y verificar que sean los\nesperados:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "assert grouped_with_weights.overall[\"selection_rate\"] == selection_rate(\n    y_test, y_pred, sample_weight=random_weights\n)\nassert grouped_with_weights.overall[\"fbeta_06\"] == skm.fbeta_score(\n    y_test, y_pred, beta=0.6, sample_weight=random_weights\n)\nprint(grouped_with_weights.overall)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tambi\u00e9n podemos ver el efecto sobre la m\u00e9trica que se eval\u00faa en los\nsubgrupos:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "grouped_with_weights.by_group"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Cuantificaci\u00f3n de disparidades\n==============================\n\nAhora sabemos que nuestro modelo est\u00e1 seleccionando individuos que son\nmujeres mucho menos a menudo que los hombres. Hay un efecto similar\ncuando examinando los resultados por raza, y los negros son\nseleccionados con mucha menos frecuencia que blancos (y los clasificados\ncomo \\'otros\\'). Sin embargo, hay muchos casos en los que presentar\ntodos estos n\u00fameros a la vez no ser\u00e1 \u00fatil (por ejemplo, un tablero de\nalto nivel que monitorea el desempe\u00f1o del modelo). Fairlearn ofrece\nvarios medios de agregar m\u00e9tricas en los subgrupos, de modo que las\ndisparidades pueden cuantificarse f\u00e1cilmente.\n\nLa m\u00e1s simple de estas agregaciones es `group_min()`, que informa el\nvalor m\u00ednimo visto para un subgrupo para cada m\u00e9trica subyacente\n(tambi\u00e9n proporcionamos `group_max()`). Esto es \u00fatil si hay un mandato\nde que \\\"ning\u00fan subgrupo debe tener un `fbeta_score()` de menos de\n0.6\\\". Podemos evaluar los valores m\u00ednimos f\u00e1cilmente:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "grouped_on_race.group_min()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Como se se\u00f1al\u00f3 anteriormente, las tasas de selecci\u00f3n var\u00edan mucho seg\u00fan\nla raza y el sexo. Esto se puede cuantificar en t\u00e9rminos de una\ndiferencia entre el subgrupo con el valor m\u00e1s alto de la m\u00e9trica y el\nsubgrupo con el valor m\u00e1s bajo. Para esto, proporcionamos el m\u00e9todo\n`difference(method ='between_groups)`:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "grouped_on_race.difference(method=\"between_groups\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tambi\u00e9n podemos evaluar la diferencia relativa que corresponde al valor\ntotal de la m\u00e9trica. En este caso tomamos el valor absoluto, de modo que\nel el resultado es siempre positivo:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "grouped_on_race.difference(method=\"to_overall\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Hay situaciones en las que conocer los radios de las m\u00e9tricas evaluadas\nen los subgrupos es m\u00e1s \u00fatil. Para ello tenemos el m\u00e9todo `ratio()`.\nPodemos tomar las relaciones entre los valores m\u00ednimo y m\u00e1ximo de cada\nm\u00e9trica:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "grouped_on_race.ratio(method=\"between_groups\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tambi\u00e9n podemos calcular los radios relativos al valor general de cada\nm\u00e9trica. De manera an\u00e1loga a las diferencias, las proporciones est\u00e1n\nsiempre en el rango :math: \\`\\[0,1\\]\\`:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "grouped_on_race.ratio(method=\"to_overall\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Intersecci\u00f3n de caracter\u00edsticas\n===============================\n\nHasta ahora, solo hemos considerado una caracter\u00edstica sensible a la\nvez, y ya hemos encontrado algunos problemas graves en nuestros datos de\nejemplo. Sin embargo, a veces se pueden esconder problemas graves en las\nintersecciones de caracter\u00edsticas. Por ejemplo, el [Proyecto Gender\nShades](https://www.media.mit.edu/projects/gender-shades/overview/)\ndescubri\u00f3 que los algoritmos de reconocimiento facial funcionaban peor\npara los negros que los blancos, y tambi\u00e9n peor para las mujeres que\npara los hombres (a pesar de la alta puntuaci\u00f3n de precisi\u00f3n). Adem\u00e1s,\nel rendimiento en mujeres negras fue *terrible*. Podemos examinar las\nintersecciones de caracter\u00edsticas sensibles pasando varias columnas para\nel constructor `fairlearn.metrics.MetricFrame`{.interpreted-text\nrole=\"class\"}:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "grouped_on_race_and_sex = MetricFrame(\n    metrics=metric_fns,\n    y_true=y_test,\n    y_pred=y_pred,\n    sensitive_features=A_test[[\"race\", \"sex\"]]\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Los valores generales no han cambiado, pero la tabla `by_group` ahora\nmuestra las intersecciones entre subgrupos:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "assert (grouped_on_race_and_sex.overall == grouped_on_race.overall).all()\ngrouped_on_race_and_sex.by_group"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Las agregaciones a\u00fan se realizan en todos los subgrupos para cada\nm\u00e9trica, para que cada uno contin\u00fae reduci\u00e9ndose a un solo valor. Si\nmiramos `group_min()`, vemos que violamos el mandato que especificamos\npara `fbeta_score()` sugerido arriba (para mujeres con una raza de\n\\'Otro\\'):\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "grouped_on_race_and_sex.group_min()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Mirando el m\u00e9todo `ratio()`, vemos que la disparidad es peor\n(espec\u00edficamente entre hombres blancos y mujeres negras, si revisamos la\ntabla `by_group`):\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "grouped_on_race_and_sex.ratio(method=\"between_groups\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Funciones de control\n====================\n\nHay otra forma en que podemos dividir nuestros datos. Tenemos\n(\\*completamente inventadas\\*) caracter\u00edsticas para los puntajes\ncrediticios de las personas (en tres rangos) y tambi\u00e9n el tama\u00f1o del\npr\u00e9stamo solicitado (grande o peque\u00f1o). En el escenario de pr\u00e9stamo, es\naceptable que las personas con puntajes crediticios altos sean\nseleccionadas con m\u00e1s frecuencia que las personas con puntajes\ncrediticios bajos. Sin embargo, dentro de cada rango de puntaje\ncrediticio, no queremos una disparidad entre (digamos) mujeres negras y\nhombres blancos. Para ejemplificar estos casos, tenemos el concepto de\n*funciones de control*.\n\nLas funciones de control son introducidas por el argumento\n`control_features =` del objeto\n`fairlearn.metrics.MetricFrame`{.interpreted-text role=\"class\"}:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "cond_credit_score = MetricFrame(\n    metrics=metric_fns,\n    y_true=y_test,\n    y_pred=y_pred,\n    sensitive_features=A_test[[\"race\", \"sex\"]],\n    control_features=A_test[\"Credit Score\"]\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Esto tiene un efecto inmediato en la propiedad `overall`. En lugar de\ntener un valor para cada m\u00e9trica, ahora tenemos un valor para cada valor\n\u00fanico de la funci\u00f3n de control:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "cond_credit_score.overall"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "La propiedad `by_group` es demostrada de manera similar:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "cond_credit_score.by_group"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Los agregados de datos tambi\u00e9n se eval\u00faan una vez para cada grupo\nidentificado por la funci\u00f3n de control:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "cond_credit_score.group_min()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Y:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "cond_credit_score.ratio(method=\"between_groups\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "En nuestros datos, vemos que tenemos una escasez de resultados positivos\npara aquellos que no blancos y que tienen altos ingresos, lo que afecta\nsignificativamente los agregados de datos.\n\nPodemos seguir agregando m\u00e1s funciones de control:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "cond_both = MetricFrame(\n    metrics=metric_fns,\n    y_true=y_test,\n    y_pred=y_pred,\n    sensitive_features=A_test[[\"race\", \"sex\"]],\n    control_features=A_test[[\"Loan Size\", \"Credit Score\"]]\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "La propiedad `overall` se desglosa en m\u00e1s valores:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "cond_both.overall"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Al igual que la propiedad `by_groups`, donde los valores `NaN` indica\nque no hab\u00eda muestras en la celda:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "cond_both.by_group"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Los agregados de datos se comportan de manera similar. A estas alturas,\nestamos teniendo problemas importantes con intersecciones poco pobladas.\nConsideremos:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def member_counts(y_true, y_pred):\n    assert len(y_true) == len(y_pred)\n    return len(y_true)\n\n\ncounts = MetricFrame(\n    metrics=member_counts,\n    y_true=y_test,\n    y_pred=y_pred,\n    sensitive_features=A_test[[\"race\", \"sex\"]],\n    control_features=A_test[[\"Loan Size\", \"Credit Score\"]]\n)\n\ncounts.by_group"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Recordemos que `NaN` indica que no hubo individuos en una celda -\n`member_counts()` ni siquiera habr\u00e1 sido llamado.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Exportando desde MetricFrame\n============================\n\nA veces, necesitamos extraer nuestros datos para usarlos en otras\nherramientas. Para esto, podemos usar el m\u00e9todo\n:py`pandas.DataFrame.to_csv`{.interpreted-text role=\"meth\"}, ya que\n:py`~fairlearn.metrics.MetricFrame.by_group`{.interpreted-text\nrole=\"meth\"} ser\u00e1 de tipo `pandas.DataFrame`{.interpreted-text\nrole=\"class\"} (o en algunos casos, ser\u00e1 de tipo\n`pandas.Series`{.interpreted-text role=\"class\"}, pero tiene un m\u00e9todo\nsimilar :py`~ pandas.Series.to_csv`{.interpreted-text role=\"meth\"}):\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "csv_output = cond_credit_score.by_group.to_csv()\nprint(csv_output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "El m\u00e9todo :py`pandas.DataFrame.to_csv`{.interpreted-text role=\"meth\"}\ntiene una gran cantidad de argumentos para controlar el CSV exportado.\nPor ejemplo, puede escribir directamente a un archivo CSV, en lugar de\ndevolver una cadena de caracteres (como se mostr\u00f3 anteriormente).\n\nLa propiedad `~ fairlearn.metrics.MetricFrame.overall`{.interpreted-text\nrole=\"meth\"} puede manejarse de manera similar, en los casos en que no\nsea un escalar.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}