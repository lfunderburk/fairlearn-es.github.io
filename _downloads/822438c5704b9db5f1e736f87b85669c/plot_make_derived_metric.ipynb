{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Obteniendo m\u00e9tricas derivadas\n=============================\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Este notebook demuestra el uso de la funci\u00f3n\n`fairlearn.metrics.make_derived_metric`{.interpreted-text role=\"func\"}.\nMuchos algoritmos de aprendizaje autom\u00e1tico de orden superior (como los\nsintonizadores de hiperpar\u00e1metros) hacen uso de m\u00e9tricas escalares al\ndecidir c\u00f3mo proceder. Mientras que\n`fairlearn.metrics.MetricFrame`{.interpreted-text role=\"class\"} tiene la\ncapacidad de producir tales escalares a trav\u00e9s de sus funciones de\nagregaci\u00f3n, su API no se ajusta a la que normalmente esperado por estos\nalgoritmos. La funci\u00f3n\n`~ fairlearn.metrics.make_derived_metric`{.interpreted-text role=\"func\"}\nexiste para solucionar este problema.\n\nObteniendo los datos\n====================\n\n\\* Esta secci\u00f3n se puede omitir. Simplemente crea un conjunto de datos\npara fines ilustrativos \\*\n\nUtilizaremos el conocido conjunto de datos UCI \\'Adultos\\' como base de\nesta demostraci\u00f3n. Esto no es para un escenario de pr\u00e9stamos, pero\nconsideraremos como uno para los prop\u00f3sitos de este ejemplo. Usaremos\nlas columnas \\'raza\\' y \\'sexo\\' (recortando la primera a tres valores\n\u00fanicos), y fabricaremos bandas de puntaje crediticio y tama\u00f1os de\npr\u00e9stamos a partir de otras columnas. Comenzamos con algunas\ndeclaraciones de \\`importaci\u00f3n\\`:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import functools\nimport numpy as np\n\nimport sklearn.metrics as skm\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.datasets import fetch_openml\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.compose import make_column_selector as selector\nfrom sklearn.pipeline import Pipeline\nfrom fairlearn.metrics import MetricFrame, make_derived_metric\nfrom fairlearn.metrics import accuracy_score_group_min"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A continuaci\u00f3n, importamos los datos, eliminando las filas a las que les\nfaltan datos:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "data = fetch_openml(data_id=1590, as_frame=True)\nX_raw = data.data\ny = (data.target == \">50K\") * 1\nA = X_raw[[\"race\", \"sex\"]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ahora vamos a preprocesar los datos. Antes de aplicar cualquier\ntransformaci\u00f3n, primero dividimos los datos en conjuntos de prueba y de\nentrenamiento. Todas las transformaciones que usemos se aplicar\u00e1n en el\nconjunto datos de entrenamiento y luego aplicada al conjunto de prueba.\nEsto asegura que los datos no se filtren entre los dos conjuntos (esto\nes un serio pero sutil [problema en el aprendizaje\nautom\u00e1tico](https://en.wikipedia.org/wiki/Leakage_(machine_learning))).\nPrimero dividimos los datos:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "(X_train, X_test, y_train, y_test, A_train, A_test) = train_test_split(\n    X_raw, y, A, test_size=0.3, random_state=12345, stratify=y\n)\n\n# Aseg\u00farese de que los \u00edndices est\u00e9n alineados entre X, y, A\n# en las Series de conjuntos de prueba y entrenamiento.\n\nX_train = X_train.reset_index(drop=True)\nX_test = X_test.reset_index(drop=True)\ny_train = y_train.reset_index(drop=True)\ny_test = y_test.reset_index(drop=True)\nA_train = A_train.reset_index(drop=True)\nA_test = A_test.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A continuaci\u00f3n, construimos dos objetos\n`~ sklearn.pipeline.Pipeline`{.interpreted-text role=\"class\"} para\nprocesar las columnas, una para datos num\u00e9ricos y la otra para datos\ncateg\u00f3ricos. Ambos imputan valores perdidos; la diferencia es si los\ndatos est\u00e1n escalados (columnas num\u00e9ricas) o tienen codificaci\u00f3n one-hot\n(columnas categ\u00f3ricas). La imputaci\u00f3n de datos no presentes generalmente\ndeben hacerse con cuidado, ya que pueden introducirse prejuicios. Por\nsupuesto, eliminar filas con los datos no presentes tambi\u00e9n puede causar\nproblemas, si subgrupos de datos tienen datos de peor calidad.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "numeric_transformer = Pipeline(\n    steps=[\n        (\"impute\", SimpleImputer()),\n        (\"scaler\", StandardScaler()),\n    ]\n)\ncategorical_transformer = Pipeline(\n    [\n        (\"impute\", SimpleImputer(strategy=\"most_frequent\")),\n        (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\")),\n    ]\n)\npreprocessor = ColumnTransformer(\n    transformers=[\n        (\"num\", numeric_transformer, selector(dtype_exclude=\"category\")),\n        (\"cat\", categorical_transformer, selector(dtype_include=\"category\")),\n    ]\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Con nuestro preprocesador definido, ahora podemos construir un nueva\npipeline que incluye un Estimador:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "unmitigated_predictor = Pipeline(\n    steps=[\n        (\"preprocessor\", preprocessor),\n        (\n            \"classifier\",\n            LogisticRegression(solver=\"liblinear\", fit_intercept=True),\n        ),\n    ]\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Con la pipeline completamente definida, primero podemos entrenarla con\nlos datos de entrenamiento y luego generar predicciones de los datos de\nprueba.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "unmitigated_predictor.fit(X_train, y_train)\ny_pred = unmitigated_predictor.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Creando una m\u00e9trica derivada\n============================\n\nSuponga que nuestra m\u00e9trica clave es la puntuaci\u00f3n de precisi\u00f3n y lo que\nm\u00e1s nos interesa es asegur\u00e1ndose de que exceda alg\u00fan l\u00edmite\n(\\\"threshold\\\") para todos los subgrupos Podr\u00edamos usar\n`~ fairlearn.metrics.MetricFrame`{.interpreted-text role=\"class\"} como\nsigue:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "acc_frame = MetricFrame(\n    metrics=skm.accuracy_score,\n    y_true=y_test,\n    y_pred=y_pred,\n    sensitive_features=A_test[\"sex\"]\n)\nprint(\"Minimum accuracy_score: \", acc_frame.group_min())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Podemos crear una funci\u00f3n para realizar esto en una sola llamada\n\n:   usando `~ fairlearn.metrics.make_derived_metric`{.interpreted-text\n    role=\"func\"}. Esto toma los siguientes argumentos (que siempre deben\n    ser suministrados como argumentos de palabra clave):\n\n    -   `metric =`{.sourceCode}, la funci\u00f3n m\u00e9trica base\n\n    - `transform =`{.sourceCode}, el nombre de la transformaci\u00f3n de agregaci\u00f3n\n\n    :   para realizar. Para esta demostraci\u00f3n, esto ser\u00eda\n        `'group_min'`{.sourceCode}\n\n    \\- `sample_param_names =`{.sourceCode}, una lista de nombres de\n    par\u00e1metros que debe tratarse como muestra par\u00e1metros. Esto es\n    opcional y por defecto es `['sample_weight']`{.sourceCode} que es\n    apropiado para muchos m\u00e9tricas en [scikit-learn]{.title-ref}.\n\n    El resultado es una nueva funci\u00f3n con la misma firma que el m\u00e9trica\n    base, que acepta dos argumentos adicionales:\n\n    \\- `sensitive_features =`{.sourceCode} para especificar las\n    caracter\u00edsticas sensibles que definen los subgrupos -\n    `m\u00e9todo =`{.sourceCode} para ajustar c\u00f3mo la transformaci\u00f3n de\n    agregaci\u00f3n opera. Esto corresponde al mismo argumento en :meth:\n    [fairlearn.metrics.MetricFrame.difference]{.title-ref} y\n\n<!-- -->\n\nmeth\n\n:   [fairlearn.metrics.MetricFrame.ratio]{.title-ref}\n\n> Para el caso actual, no necesitamos el argumento\n> `method =`{.sourceCode}, ya que estamos tomando el valor m\u00ednimo.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "my_acc = make_derived_metric(metric=skm.accuracy_score, transform=\"group_min\")\nmy_acc_min = my_acc(y_test, y_pred, sensitive_features=A_test[\"sex\"])\nprint(\"Minimum accuracy_score: \", my_acc_min)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Para mostrar que la funci\u00f3n resultante tambi\u00e9n funciona con\nponderaciones de muestra:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "random_weights = np.random.rand(len(y_test))\n\nacc_frame_sw = MetricFrame(\n    metrics=skm.accuracy_score,\n    y_true=y_test,\n    y_pred=y_pred,\n    sensitive_features=A_test[\"sex\"],\n    sample_params={\"sample_weight\": random_weights},\n)\n\nfrom_frame = acc_frame_sw.group_min()\nfrom_func = my_acc(\n    y_test,\n    y_pred,\n    sensitive_features=A_test[\"sex\"],\n    sample_weight=random_weights,\n)\n\nprint(\"From MetricFrame:\", from_frame)\nprint(\"From function   :\", from_func)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "La funci\u00f3n devuelta tambi\u00e9n puede manejar par\u00e1metros que no son\npar\u00e1metros muestra. Considere\n`sklearn.metrics.fbeta_score`{.interpreted-text role=\"func\"}, que tiene\nun argumento requerido `beta =`{.sourceCode} (y supongamos que esta vez\nlo que m\u00e1s nos interesa es la diferencia m\u00e1xima con el valor total).\nPrimero evaluamos esto con\n`fairlearn.metrics.MetricFrame`{.interpreted-text role=\"class\"}:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fbeta_03 = functools.partial(skm.fbeta_score, beta=0.3)\nfbeta_03.__name__ = \"fbeta_score__beta_0.3\"\n\nbeta_frame = MetricFrame(\n    metrics=fbeta_03,\n    y_true=y_test,\n    y_pred=y_pred,\n    sensitive_features=A_test[\"sex\"],\n    sample_params={\"sample_weight\": random_weights},\n)\nbeta_from_frame = beta_frame.difference(method=\"to_overall\")\n\nprint(\"From frame:\", beta_from_frame)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Y a continuaci\u00f3n, creamos una funci\u00f3n para evaluar lo mismo. Tenga en\ncuenta que no necesitamos usar la funci\u00f3n\n`functools.partial`{.interpreted-text role=\"func\"} para enlazar el\nargumento `beta =`{.sourceCode}:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "beta_func = make_derived_metric(metric=skm.fbeta_score, transform=\"difference\")\n\nbeta_from_func = beta_func(\n    y_test,\n    y_pred,\n    sensitive_features=A_test[\"sex\"],\n    beta=0.3,\n    sample_weight=random_weights,\n    method=\"to_overall\",\n)\n\nprint(\"From function:\", beta_from_func)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "M\u00e9tricas pregeneradas\n=====================\n\nProporcionamos una serie de m\u00e9tricas pregeneradas para cubrir casos de\nuso comunes. Por ejemplo, proporcionamos la funci\u00f3n\n`precision_score_group_min ()`{.sourceCode} para encontrar la\ncalificaci\u00f3n de precisi\u00f3n m\u00ednima:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from_myacc = my_acc(y_test, y_pred, sensitive_features=A_test[\"race\"])\n\nfrom_pregen = accuracy_score_group_min(\n    y_test, y_pred, sensitive_features=A_test[\"race\"]\n)\n\nprint(\"From my function :\", from_myacc)\nprint(\"From pregenerated:\", from_pregen)\nassert from_myacc == from_pregen"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}